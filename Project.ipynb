
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.sparse import csr_matrix
from sklearn.neighbors import NearestNeighbors
DATASET_LINK='http://files.grouplens.org/datasets/movielens/ml-100k.zip'
!wget -nc http://files.grouplens.org/datasets/movielens/ml-100k.zip
!unzip -n ml-100k.zip
File ‘ml-100k.zip’ already there; not retrieving.

Archive:  ml-100k.zip
Loading MovieLens dataset
Loading u.info -- The number of users, items, and ratings in the u data set.

overall_stats = pd.read_csv('ml-100k/u.info', header=None)
print("Details of users, items and ratings involved in the loaded movielens dataset: ",list(overall_stats[0]))
Details of users, items and ratings involved in the loaded movielens dataset:  ['943 users', '1682 items', '100000 ratings']
Loading u.data -- The full u data set, 100000 ratings by 943 users on 1682 items.

          Each user has rated at least 20 movies.  Users and items are
          numbered consecutively from 1.  The data is randomly ordered. This is a tab separated list of 
         user id | item id | rating | timestamp. 
          The time stamps are unix seconds since 1/1/1970 UTC 
## same item id is same as movie id, item id column is renamed as movie id
column_names1 = ['user id','movie id','rating','timestamp']
dataset = pd.read_csv('ml-100k/u.data', sep='\t',header=None,names=column_names1)
dataset.head() 
user id	movie id	rating	timestamp
0	196	242	3	881250949
1	186	302	3	891717742
2	22	377	1	878887116
3	244	51	2	880606923
4	166	346	1	886397596
len(dataset), max(dataset['movie id']),min(dataset['movie id'])
(100000, 1682, 1)
Loading u.item -- Information about the items (movies); this is a tab separated
list of
          movie id | movie title | release date | video release date |
          IMDb URL | unknown | Action | Adventure | Animation |
          Children's | Comedy | Crime | Documentary | Drama | Fantasy |
          Film-Noir | Horror | Musical | Mystery | Romance | Sci-Fi |
          Thriller | War | Western |
          The last 19 fields are the genres, a 1 indicates the movie
          is of that genre, a 0 indicates it is not; movies can be in
          several genres at once.
          The movie ids are the ones used in the u.data data set.
d = 'movie id | movie title | release date | video release date | IMDb URL | unknown | Action | Adventure | Animation | Children | Comedy | Crime | Documentary | Drama | Fantasy | Film-Noir | Horror | Musical | Mystery | Romance | Sci-Fi | Thriller | War | Western'
column_names2 = d.split(' | ')
column_names2
['movie id',
 'movie title',
 'release date',
 'video release date',
 'IMDb URL',
 'unknown',
 'Action',
 'Adventure',
 'Animation',
 'Children',
 'Comedy',
 'Crime',
 'Documentary',
 'Drama',
 'Fantasy',
 'Film-Noir',
 'Horror',
 'Musical',
 'Mystery',
 'Romance',
 'Sci-Fi',
 'Thriller',
 'War',
 'Western']
items_dataset = pd.read_csv('ml-100k/u.item', sep='|',header=None,names=column_names2,encoding='latin-1')
items_dataset
movie id	movie title	release date	video release date	IMDb URL	unknown	Action	Adventure	Animation	Children	Comedy	Crime	Documentary	Drama	Fantasy	Film-Noir	Horror	Musical	Mystery	Romance	Sci-Fi	Thriller	War	Western
0	1	Toy Story (1995)	01-Jan-1995	NaN	http://us.imdb.com/M/title-exact?Toy%20Story%2...	0	0	0	1	1	1	0	0	0	0	0	0	0	0	0	0	0	0	0
1	2	GoldenEye (1995)	01-Jan-1995	NaN	http://us.imdb.com/M/title-exact?GoldenEye%20(...	0	1	1	0	0	0	0	0	0	0	0	0	0	0	0	0	1	0	0
2	3	Four Rooms (1995)	01-Jan-1995	NaN	http://us.imdb.com/M/title-exact?Four%20Rooms%...	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	1	0	0
3	4	Get Shorty (1995)	01-Jan-1995	NaN	http://us.imdb.com/M/title-exact?Get%20Shorty%...	0	1	0	0	0	1	0	0	1	0	0	0	0	0	0	0	0	0	0
4	5	Copycat (1995)	01-Jan-1995	NaN	http://us.imdb.com/M/title-exact?Copycat%20(1995)	0	0	0	0	0	0	1	0	1	0	0	0	0	0	0	0	1	0	0
...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...
1677	1678	Mat' i syn (1997)	06-Feb-1998	NaN	http://us.imdb.com/M/title-exact?Mat%27+i+syn+...	0	0	0	0	0	0	0	0	1	0	0	0	0	0	0	0	0	0	0
1678	1679	B. Monkey (1998)	06-Feb-1998	NaN	http://us.imdb.com/M/title-exact?B%2E+Monkey+(...	0	0	0	0	0	0	0	0	0	0	0	0	0	0	1	0	1	0	0
1679	1680	Sliding Doors (1998)	01-Jan-1998	NaN	http://us.imdb.com/Title?Sliding+Doors+(1998)	0	0	0	0	0	0	0	0	1	0	0	0	0	0	1	0	0	0	0
1680	1681	You So Crazy (1994)	01-Jan-1994	NaN	http://us.imdb.com/M/title-exact?You%20So%20Cr...	0	0	0	0	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0
1681	1682	Scream of Stone (Schrei aus Stein) (1991)	08-Mar-1996	NaN	http://us.imdb.com/M/title-exact?Schrei%20aus%...	0	0	0	0	0	0	0	0	1	0	0	0	0	0	0	0	0	0	0
1682 rows × 24 columns
movie_dataset = items_dataset[['movie id','movie title']]
movie_dataset.head()
movie id	movie title
0	1	Toy Story (1995)
1	2	GoldenEye (1995)
2	3	Four Rooms (1995)
3	4	Get Shorty (1995)
4	5	Copycat (1995)
Looking at length of original items_dataset and length of unique combination of rows in items_dataset after removing movie id column

## looking at length of original items_dataset and length of unique combination of rows in items_dataset after removing movie id column
len(items_dataset.groupby(by=column_names2[1:])),len(items_dataset)
(1664, 1682)
We can see there are 18 extra movie id's for already mapped movie title and the same duplicate movie id is assigned to the user in the user-item dataset.

Merging required datasets
merged_dataset = pd.merge(dataset, movie_dataset, how='inner', on='movie id')
merged_dataset.head()
user id	movie id	rating	timestamp	movie title
0	196	242	3	881250949	Kolya (1996)
1	63	242	3	875747190	Kolya (1996)
2	226	242	5	883888671	Kolya (1996)
3	154	242	3	879138235	Kolya (1996)
4	306	242	5	876503793	Kolya (1996)
A dataset is created from the existing merged dataset by grouping the unique user id and movie title combination and the ratings by a user to the same movie in different instances (timestamps) are averaged and stored in the new dataset.

Example of a multiple rating scenario by an user to a specific movie:

merged_dataset[(merged_dataset['movie title'] == 'Chasing Amy (1997)') & (merged_dataset['user id'] == 894)]
user id	movie id	rating	timestamp	movie title
4800	894	246	4	882404137	Chasing Amy (1997)
22340	894	268	3	879896041	Chasing Amy (1997)
refined_dataset = merged_dataset.groupby(by=['user id','movie title'], as_index=False).agg({"rating":"mean"})

refined_dataset.head()
user id	movie title	rating
0	1	101 Dalmatians (1996)	2.0
1	1	12 Angry Men (1957)	5.0
2	1	20,000 Leagues Under the Sea (1954)	3.0
3	1	2001: A Space Odyssey (1968)	4.0
4	1	Abyss, The (1989)	3.0
Exploratory data analysis
Plot the counts of each rating
Plot rating frequency of each movie
Plot the counts of each rating

we first need to get the counts of each rating from ratings data

# num_users = len(refined_dataset.rating.unique())
# num_items = len(refined_dataset.movieId.unique())
num_users = len(refined_dataset['user id'].value_counts())
num_items = len(refined_dataset['movie title'].value_counts())
print('Unique number of users in the dataset: {}'.format(num_users))
print('Unique number of movies in the dataset: {}'.format(num_items))
Unique number of users in the dataset: 943
Unique number of movies in the dataset: 1664
rating_count_df = pd.DataFrame(refined_dataset.groupby(['rating']).size(), columns=['count'])
rating_count_df
count
rating	
1.0	6083
1.5	3
2.0	11334
2.5	6
3.0	27060
3.5	19
4.0	34042
4.5	16
5.0	21130
ax = rating_count_df.reset_index().rename(columns={'index': 'rating score'}).plot('rating','count', 'bar',
    figsize=(12, 8),
    title='Count for Each Rating Score',
    fontsize=12)

ax.set_xlabel("movie rating score")
ax.set_ylabel("number of ratings")
Text(0, 0.5, 'number of ratings')
We can see that number of 1.5, 2.5, 3.5, 4.5 ratings by the users are comparitively negligible.

Ratings for the movies not seen by a user is by default considered as 0. Lets calculate and add it to the existing dataframe.

total_count = num_items * num_users
zero_count = total_count-refined_dataset.shape[0]
zero_count
1469459
# append counts of zero rating to df_ratings_cnt
rating_count_df = rating_count_df.append(
    pd.DataFrame({'count': zero_count}, index=[0.0]),
    verify_integrity=True,
).sort_index()
rating_count_df
count
0.0	1469459
1.0	6083
1.5	3
2.0	11334
2.5	6
3.0	27060
3.5	19
4.0	34042
4.5	16
5.0	21130
Number of times no rating was given (forged as 0 in this case) is a lot more than other ratings.

So let's take log transform for count values and then we can plot them to compare

# add log count
rating_count_df['log_count'] = np.log(rating_count_df['count'])
rating_count_df
count	log_count
0.0	1469459	14.200405
1.0	6083	8.713253
1.5	3	1.098612
2.0	11334	9.335562
2.5	6	1.791759
3.0	27060	10.205812
3.5	19	2.944439
4.0	34042	10.435350
4.5	16	2.772589
5.0	21130	9.958449
rating_count_df = rating_count_df.reset_index().rename(columns={'index': 'rating score'})
rating_count_df
rating score	count	log_count
0	0.0	1469459	14.200405
1	1.0	6083	8.713253
2	1.5	3	1.098612
3	2.0	11334	9.335562
4	2.5	6	1.791759
5	3.0	27060	10.205812
6	3.5	19	2.944439
7	4.0	34042	10.435350
8	4.5	16	2.772589
9	5.0	21130	9.958449
ax = rating_count_df.plot('rating score', 'log_count', 'bar', figsize=(12, 8),
    title='Count for Each Rating Score (in Log Scale)',
    logy=True,
    fontsize=12,)

ax.set_xlabel("movie rating score")
ax.set_ylabel("number of ratings")
Text(0, 0.5, 'number of ratings')

We have already observed from the before bar plot that ratings 3 and 4 are given in more numbers by the users. Even the above graph suggests the same.

Take away from this plot is by the number of missing ratings, we can estimate the level of sparsity in the matrix we are going to form.

Plot rating frequency of all movies

refined_dataset.head()
user id	movie title	rating
0	1	101 Dalmatians (1996)	2.0
1	1	12 Angry Men (1957)	5.0
2	1	20,000 Leagues Under the Sea (1954)	3.0
3	1	2001: A Space Odyssey (1968)	4.0
4	1	Abyss, The (1989)	3.0
# get rating frequency
movies_count_df = pd.DataFrame(refined_dataset.groupby('movie title').size(), columns=['count'])
movies_count_df.head()
count
movie title	
'Til There Was You (1997)	9
1-900 (1994)	5
101 Dalmatians (1996)	109
12 Angry Men (1957)	125
187 (1997)	41
# plot rating frequency of all movies
ax = movies_count_df \
    .sort_values('count', ascending=False) \
    .reset_index(drop=True) \
    .plot(
        figsize=(12, 8),
        title='Rating Frequency of All Movies',
        fontsize=12
    )
ax.set_xlabel("movie Id")
ax.set_ylabel("number of ratings")
Text(0, 0.5, 'number of ratings')

As the size of MovieLens dataset picked for this project is small. There is no need of removing rarely rated movies or users who has given rating for fewer movies.

Also because the dataset considered is small, we do not see the long-tail property which will be the scenario with the distribution of ratings.

If the dataset is larger, then (this can be referred when we do similar kind of tasks with a larger dataset, just for future reference)

The distribution of ratings among movies often satisfies a property in real-world settings, which is referred to as the long-tail property. According to this property, only a small fraction of the items are rated frequently. Such items are referred to as popular items. The vast majority of items are rated rarely. This results in a highly skewed distribution of the underlying ratings.
